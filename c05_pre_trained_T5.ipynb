{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMUWqZzV4TjplvE7gEL8x1W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from transformers import TFT5ForConditionalGeneration, AutoTokenizer"],"metadata":{"id":"jsHkPci-fZWk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"_US00x2nrYqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_checkpoint = \"/content/gdrive/MyDrive/Transformers_files/scratch_T5_squad\"\n","modelo_prueba = TFT5ForConditionalGeneration.from_pretrained(model_checkpoint)\n","tokenizer_prueba = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"id":"-CwM8lOig6tW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def modelo_pre_trained_T5(question, context):\n","\n","  input_text =  f\"answer_me: {question} context: {context} </s>\"\n","  encoded_input = tokenizer_prueba(input_text, return_tensors='tf', pad_to_max_length=True, truncation=True, max_length=254)\n","  input_ids = encoded_input[\"input_ids\"]\n","  attention_mask = encoded_input[\"attention_mask\"]\n","  generated_answer = modelo_prueba.generate(input_ids, attention_mask=attention_mask)\n","  return tokenizer_prueba.decode(generated_answer.numpy()[0], clean_up_tokenization_spaces=True, skip_special_tokens=True)\n"],"metadata":{"id":"9rneHgO2hWgZ"},"execution_count":null,"outputs":[]}]}