{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5cVMAa10LJXP"},"outputs":[],"source":["!pip install 'optimum[onnxruntime-gpu]'\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TY77hH3gYJz9"},"outputs":[],"source":["# !pip install tf2onnx\n","# import tf2onnx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22775,"status":"ok","timestamp":1669171288466,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"},"user_tz":300},"id":"znS6pAfOMf3F","outputId":"acbdaebc-6155-4166-8007-ec48aef3e5de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1669173802528,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"},"user_tz":300},"id":"KqwvhCdtM1NC","outputId":"a4923ec1-019e-4952-d425-ab70375077cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Transformers_files\n"]}],"source":["# %pwd\n","%cd \"/content/gdrive/MyDrive/Transformers_files\""]},{"cell_type":"markdown","metadata":{"id":"PabuKap2MPjj"},"source":["## Cargar el transformers y convertirlo a objeto onnx. Guardar"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":391,"status":"ok","timestamp":1669174062004,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"},"user_tz":300},"id":"-XwVsUszMFWn"},"outputs":[],"source":["from pathlib import Path\n","from transformers import AutoTokenizer, pipeline\n","from optimum.onnxruntime import ORTModelForQuestionAnswering\n","\n","# model_id = \"deepset/roberta-base-squad2\"\n","model_id = 'scratch_roberta_squad'\n","onnx_path = Path(\"onnx_scratch_roberta\")\n","\n","task = \"question-answering\"\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnEtpgqqOOWl","executionInfo":{"status":"ok","timestamp":1669174213550,"user_tz":300,"elapsed":132089,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"}},"outputId":"9747aa25-cfcc-442e-b367-47081819f76e"},"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaForQuestionAnswering.\n","\n","All the layers of TFRobertaForQuestionAnswering were initialized from the model checkpoint at scratch_roberta_squad.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForQuestionAnswering for predictions without further training.\n"]}],"source":["# load vanilla transformers and convert to onnx\n","model = ORTModelForQuestionAnswering.from_pretrained(model_id, from_transformers = True)\n","# tokenizer = AutoTokenizer.from_pretrained(model_id)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3825,"status":"ok","timestamp":1669174250828,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"},"user_tz":300},"id":"T89m_lZROTg0","outputId":"bcb1ef11-4206-4c7c-b117-4b7112de1808"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('onnx_scratch_roberta/tokenizer_config.json',\n"," 'onnx_scratch_roberta/special_tokens_map.json',\n"," 'onnx_scratch_roberta/vocab.json',\n"," 'onnx_scratch_roberta/merges.txt',\n"," 'onnx_scratch_roberta/added_tokens.json',\n"," 'onnx_scratch_roberta/tokenizer.json')"]},"metadata":{},"execution_count":28}],"source":["# save onnx checkpoint and tokenizer\n","model.save_pretrained(onnx_path)\n","tokenizer.save_pretrained(onnx_path)"]},{"cell_type":"markdown","metadata":{"id":"mgUznj-8Nsff"},"source":["## Optimizar el modelo"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10249,"status":"ok","timestamp":1669174279671,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"},"user_tz":300},"id":"eq1yEUD7Nqej","outputId":"d07de92b-7157-4a50-cf99-1a205683dab8"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:onnxruntime.transformers.optimizer:Model producer not matched: Expected \"pytorch\", Got \"tf2onnx\".Please specify correct --model_type parameter.\n"]},{"output_type":"execute_result","data":{"text/plain":["PosixPath('onnx_scratch_roberta')"]},"metadata":{},"execution_count":29}],"source":["from optimum.onnxruntime import ORTOptimizer\n","from optimum.onnxruntime.configuration import OptimizationConfig\n","\n","# create ORTOptimizer and define optimization configuration\n","optimizer = ORTOptimizer.from_pretrained(model)\n","optimization_config = OptimizationConfig(optimization_level=99) # enable all optimizations\n","\n","# apply the optimization configuration to the model\n","optimizer.optimize(\n","    save_dir=onnx_path,\n","    optimization_config=optimization_config) "]},{"cell_type":"markdown","metadata":{"id":"hwwCL2kmOvKW"},"source":["## Después de optimizar el modelo, podemos acelerarlo más con  cuantizándolo con ORTQuantizer"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"m3Gn_3nvOujl","executionInfo":{"status":"ok","timestamp":1669174334679,"user_tz":300,"elapsed":25137,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"}}},"outputs":[],"source":["from optimum.onnxruntime import ORTQuantizer\n","from optimum.onnxruntime.configuration import AutoQuantizationConfig\n","\n","# create ORTQuantizer and define quantization configuration\n","dynamic_quantizer = ORTQuantizer.from_pretrained(model)\n","dqconfig = AutoQuantizationConfig.avx512_vnni(is_static=False, per_channel=False)\n","\n","# apply the quantization configuration to the model\n","model_quantized_path = dynamic_quantizer.quantize(\n","    save_dir=onnx_path,\n","    quantization_config=dqconfig)"]},{"cell_type":"markdown","metadata":{"id":"3ZAedv5HP9Ol"},"source":["### Revisar diferencia de pesos de los modelos"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1669174389652,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"},"user_tz":300},"id":"IDypcEjLPd2j","outputId":"abbe3b07-b299-4efe-d921-9fd53ad7a2e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model file size: 473.67 MB\n","Quantized Model file size: 231.00 MB\n"]}],"source":["import os\n","\n","# get model file size\n","size = os.path.getsize(onnx_path / \"model_optimized.onnx\")/(1024*1024)\n","quantized_model = os.path.getsize(onnx_path / \"model_quantized.onnx\")/(1024*1024)\n","\n","print(f\"Model file size: {size:.2f} MB\")\n","print(f\"Quantized Model file size: {quantized_model:.2f} MB\")"]},{"cell_type":"markdown","metadata":{"id":"Ttwkk3UwQHab"},"source":["## Importar el modelo\n"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":2186,"status":"ok","timestamp":1669174618660,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"},"user_tz":300},"id":"mxe46bmyQFrS"},"outputs":[],"source":["model = ORTModelForQuestionAnswering.from_pretrained(onnx_path,file_name=\"model_quantized.onnx\")\n","tokenizer = AutoTokenizer.from_pretrained(onnx_path)\n","# from transformers import AutoModelForQuestionAnswering\n","# model = AutoModelForQuestionAnswering.from_pretrained(model_id, from_tf = True)\n","# tokenizer = AutoTokenizer.from_pretrained(model_id)"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":232,"status":"ok","timestamp":1669174691665,"user":{"displayName":"Laura Camila Cruz De Paula","userId":"00905567835013792152"},"user_tz":300},"id":"po1fpG31RRws"},"outputs":[],"source":["modelo = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYdi7pQNRS9r"},"outputs":[],"source":["modelo('pregunta acá','contexto acá')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyOnrRgNsmuA3IwFP6vqHXkK"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}